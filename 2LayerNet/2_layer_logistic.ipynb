{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "d_size = 128\n",
    "def data_generate(d_size = 128):\n",
    "    x_train = np.array([[np.random.uniform(-1,1),np.random.uniform(-1,1)]])\n",
    "    if x_train[0][0]*x_train[0][0] < x_train[0][1]:\n",
    "        label = np.array([[0]])\n",
    "    else:\n",
    "        label = np.array([[1]])\n",
    "    labels = label\n",
    "    for i in range(d_size-1):\n",
    "        data = np.array([[np.random.uniform(-1,1),np.random.uniform(-1,1)]])\n",
    "        x_train = np.concatenate((x_train,data))\n",
    "        if data[0][0]*data[0][0] < data[0][1]:\n",
    "            label = np.array([[0]])\n",
    "        else:\n",
    "            label = np.array([[1]])\n",
    "        labels = np.concatenate((labels,label))\n",
    "    return x_train,labels\n",
    "\n",
    "x_train, labels = data_generate()\n",
    "print(x_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "print(sigmoid(0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#two layer Network\n",
    "class TwoLayerNet():\n",
    "    def __init__(self):\n",
    "        self.params = {}\n",
    "        self.params['w1'] = np.random.randn(2, 2)# input - 2 , hidden 2\n",
    "        self.params['b1'] = np.zeros((2,1))\n",
    "        self.params['w2'] = np.random.randn(1,2) # hidden2 , output - 1\n",
    "        self.params['b2'] = np.zeros((1,1))\n",
    "\n",
    "    def propagation(self, x):\n",
    "        z1 = np.dot(self.params[\"w1\"],x) + self.params[\"b1\"]\n",
    "        a1 = sigmoid(z1)\n",
    "        z2 = np.dot(self.params[\"w2\"],a1) + self.params[\"b2\"]\n",
    "        a2 = sigmoid(z2)\n",
    "        #print(a2)\n",
    "        return a1,a2\n",
    "\n",
    "    def cost(self,a2,y):\n",
    "        m = y.shape[1]\n",
    "\n",
    "        cross = np.multiply(np.log(a2), y) + np.multiply(np.log(1-a2) , (1-y))\n",
    "        cost = - np.sum(cross) / m\n",
    "        cost = np.squeeze(cost)\n",
    "        return cost\n",
    "\n",
    "    def back_propagation(self, a1, a2, x, y):\n",
    "\n",
    "        dz2 = a2 - y\n",
    "        dw2 = np.dot(dz2, a1.T) / d_size\n",
    "        db2 = np.sum(dz2, axis=1, keepdims=True) / d_size\n",
    "        d_gz = 1 - np.power(a1, 2)\n",
    "        dz1 = np.dot(self.params[\"w2\"].T, dz2) * d_gz\n",
    "        dw1 = np.dot(dz1, x.T) / d_size\n",
    "        db1 = np.sum(dz1, axis=1, keepdims=True) / d_size\n",
    "\n",
    "        grads = {\"w1\": dw1,\n",
    "                 \"w2\": dw2,\n",
    "                 \"b2\": db2,\n",
    "                 \"b1\": db1}\n",
    "        return grads\n",
    "\n",
    "    def update_parameters(self, grads, lr=0.1):\n",
    "        for k in self.params.keys():\n",
    "            self.params[k] -= lr * grads[k]\n",
    "\n",
    "    def training(self, x, y, num_iter,lr=0.1):\n",
    "        for i in range(num_iter):\n",
    "            # propagation\n",
    "            a1, a2 = self.propagation(x)\n",
    "\n",
    "            # back_propagation\n",
    "            grads = self.back_propagation(a1, a2, x, y)\n",
    "\n",
    "            self.update_parameters(grads, lr=lr)\n",
    "            '''if (i % 10 == 0):\n",
    "                print(i,self.cost(a2,y) ,self.predict(x))'''\n",
    "\n",
    "    def predict(self, x,y):\n",
    "        a1, a2 = self.propagation(x)\n",
    "        predictions = abs(a2-y) < 0.5\n",
    "        #print(predictions)\n",
    "\n",
    "        return np.mean(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TwoLayerNet()\n",
    "x,y = data_generate()\n",
    "model.predict(x.T,y.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.828125\n",
      "2 0.875\n",
      "3 0.859375\n",
      "4 0.8125\n",
      "5 0.8359375\n",
      "6 0.8671875\n",
      "7 0.8203125\n",
      "8 0.828125\n",
      "9 0.8125\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    x_train, y_train = data_generate()\n",
    "    model.training(x_train.T,y_train.T,num_iter=5000,lr =0.5)\n",
    "    x_valid, y_valid = data_generate()\n",
    "    acc = model.predict(x_valid.T,y_valid.T)\n",
    "    print(i,acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_train,y_train = data_generate()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None,2])\n",
    "Y = tf.placeholder(tf.float32, shape=[None,1])\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([2,2]))\n",
    "b1 = tf.Variable(tf.random_normal([2,1]))\n",
    "w2 = tf.Variable(tf.random_normal([2,1]))\n",
    "b2 = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(tf.sigmoid(tf.matmul(X,w1)),w2) + b2)\n",
    "\n",
    "cost = - tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y) * tf.log(1-hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,Y),dtype=tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 result :  0.7421875\n",
      "1 result :  0.953125\n",
      "2 result :  0.875\n",
      "3 result :  0.859375\n",
      "4 result :  0.90625\n",
      "5 result :  0.921875\n",
      "6 result :  0.8828125\n",
      "7 result :  0.9375\n",
      "8 result :  0.9453125\n",
      "9 result :  0.9609375\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(10):\n",
    "        x_train,y_train = data_generate()\n",
    "        for step in range(5000):\n",
    "            cost_val , _ = sess.run([cost,train],feed_dict ={X : x_train, Y : y_train})\n",
    "            #if step % 1000 == 0:\n",
    "             #   print(step,cost_val)\n",
    "\n",
    "        h,c,a = sess.run([hypothesis, predicted, accuracy], feed_dict = {X: x_train,Y : y_train})\n",
    "        print(i,\"result : \",a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
